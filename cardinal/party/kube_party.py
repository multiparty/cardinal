from cardinal.party import Party
from cardinal.handlers.kube import KubeHandler


class KubeParty(Party):
    def __init__(self, workflow_config: dict, app, handler: KubeHandler):
        super(KubeParty, self).__init__(workflow_config, app, handler)

    def run(self):
        pass

    def build_pod_spec(self):
        self.specs["POD"] = ""

    def build_service_spec(self):
        self.specs["SERVICE"] = ""

    def build_config_map(self):
        """
        The config map will have:
            - the congregation workflow to be run
            - the congregation config that gets generated by build_congregation_config()
            - the cloud storage endpoint for the input dataset (eg s3://datasets/input.csv)
                * we assume that the generated pod has environment variables injected into
                when we define the pod which allow it to authenticate against the cloud storage.
                These environment variables are also present on this machine (since we're making
                API calls to aws/gcloud/azure), so we can just grab them from the environment.
        """
        self.specs["CONFIG_MAP"] = ""

    def launch_pod(self):

        if self.specs.get("POD") is None:
            self.app.logger.error("No pod spec defined.")
        self.handler.launch_pod(self.specs.get("POD"))

    def launch_service(self):

        if self.specs.get("SERVICE") is None:
            self.app.logger.error("No service spec defined.")
        self.handler.launch_service(self.specs.get("service"))

    def build_all(self):

        self.build_service_spec()
        self.build_pod_spec()
        self._exchange_ips()
        self.build_congregation_config()
        self.build_config_map()

    def launch_all(self):

        self.handler.launch_service(self.specs.get("SERVICE"))
        self.handler.launch_pod(self.specs.get("POD"))
